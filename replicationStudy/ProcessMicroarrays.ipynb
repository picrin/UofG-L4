{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {
    "collapsed": true
   },
   "source": [
    "# Replcation Study -- Myotonic Dystrophy alternative splicing\n",
    "\n",
    "Checking if our data supports previous evidence about alternative splicing.\n",
    "\n",
    "## setup\n",
    "\n",
    "- install Biopython\n",
    "- install rclone\n",
    "- setup rclone to point to my google drive (or copy the files directly from https://drive.google.com/open?id=0B0QdpQaEjDtBcF9mNHM5aWEyMzQ) \n",
    "- run setup.sh\n",
    "- install redis and run it on the standard port\n",
    "- run generateMetadata.ipynb BEFORE running this script.\n",
    "- run ComputeAS.ipynb AFTER running this script."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "# make sure this doesn't clash with anything else!\n",
    "redisDB = 2\n",
    "\n",
    "# this will wipe out only the data generated previously by this script and owned by the script (i.e. only db=redisDB)\n",
    "wipeDB = False\n",
    "\n",
    "# set this to 2**64 to get everything, or lower value for debugging\n",
    "recordNo = 10"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "import redis\n",
    "r = redis.StrictRedis(host='localhost', port=2050, db=redisDB)\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Remember about 2 weird things:\n",
    "1. The probe sequence across patients is reverse-sorted (unlike the metadata), because of how redis's lpush works, I might fix that later.\n",
    "\n",
    "2. Accessing Affy v4 coordinates needs reversing X, Y -> Y, X. I might fix that later."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Let us hack Biopython's code a little"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "# Copyright 2004 by Harry Zuzan. All rights reserved.\n",
    "# Copyright 2016 by Adam Kurkiewicz. All rights reserved.\n",
    "# This code is part of the Biopython distribution and governed by its\n",
    "# license.  Please see the LICENSE file that should have been included\n",
    "# as part of this package.\n",
    "\n",
    "\"\"\"\n",
    "Reading information from Affymetrix CEL files version 3 and 4.\n",
    "\"\"\"\n",
    "\n",
    "from __future__ import print_function\n",
    "import sys\n",
    "import struct\n",
    "\n",
    "try:\n",
    "    import numpy\n",
    "except ImportError:\n",
    "    from Bio import MissingPythonDependencyError\n",
    "    raise MissingPythonDependencyError(\n",
    "        \"Install NumPy if you want to use Bio.Affy.CelFile\")\n",
    "\n",
    "\n",
    "class ParserError(ValueError):\n",
    "    def __init__(self, *args):\n",
    "        super(ParserError, self).__init__(*args)\n",
    "\n",
    "_modeError = ParserError(\"You're trying to open an Affymetrix v4\"\n",
    "                         \" CEL file. You have to use a read binary mode,\"\n",
    "                         \" like this `open(filename \\\"rb\\\")`.\")\n",
    "\n",
    "# for debugging\n",
    "# import pprint\n",
    "# pp = pprint.PrettyPrinter(indent=4)\n",
    "\n",
    "\n",
    "class Record(object):\n",
    "    \"\"\"Stores the information in a cel file\n",
    "\n",
    "    Example usage:\n",
    "\n",
    "    >>> from Bio.Affy import CelFile\n",
    "    >>> with open(\"Affy/affy_v3_example.CEL\", \"r\") as handle:\n",
    "    ...     c = CelFile.read(handle)\n",
    "    ...\n",
    "    >>> print(c.ncols, c.nrows)\n",
    "    5 5\n",
    "    >>> print(c.intensities)\n",
    "    [[   234.    170.  22177.    164.  22104.]\n",
    "     [   188.    188.  21871.    168.  21883.]\n",
    "     [   188.    193.  21455.    198.  21300.]\n",
    "     [   188.    182.  21438.    188.  20945.]\n",
    "     [   193.  20370.    174.  20605.    168.]]\n",
    "    >>> print(c.stdevs)\n",
    "    [[   24.     34.5  2669.     19.7  3661.2]\n",
    "     [   29.8    29.8  2795.9    67.9  2792.4]\n",
    "     [   29.8    88.7  2976.5    62.   2914.5]\n",
    "     [   29.8    76.2  2759.5    49.2  2762. ]\n",
    "     [   38.8  2611.8    26.6  2810.7    24.1]]\n",
    "    >>> print(c.npix)\n",
    "    [[25 25 25 25 25]\n",
    "     [25 25 25 25 25]\n",
    "     [25 25 25 25 25]\n",
    "     [25 25 25 25 25]\n",
    "     [25 25 25 25 25]]\n",
    "\n",
    "    \"\"\"\n",
    "    def __init__(self):\n",
    "        self.version = None\n",
    "        self.GridCornerUL = None\n",
    "        self.GridCornerUR = None\n",
    "        self.GridCornerLR = None\n",
    "        self.GridCornerLL = None\n",
    "        self.DatHeader = None\n",
    "        self.Algorithm = None\n",
    "        self.AlgorithmParameters = None\n",
    "        self.NumberCells = None\n",
    "        self.intensities = None\n",
    "        self.stdevs = None\n",
    "        self.npix = None\n",
    "        self.nrows = None\n",
    "        self.ncols = None\n",
    "        self.nmask = None\n",
    "        self.mask = None\n",
    "        self.noutliers = None\n",
    "        self.outliers = None\n",
    "        self.modified = None\n",
    "\n",
    "\n",
    "def read(handle):\n",
    "    \"\"\" Reads Affymetrix CEL file and returns Record object.\n",
    "\n",
    "    CEL files version 3 and 4 are supported, and the parser attempts version detection.\n",
    "\n",
    "    Example Usage:\n",
    "\n",
    "    >>> from Bio.Affy import CelFile\n",
    "    >>> with open(\"Affy/affy_v4_example.CEL\", \"rb\") as handle:\n",
    "    ...     c = CelFile.read(handle)\n",
    "    ...\n",
    "    >>> c.version == 4\n",
    "    True\n",
    "    \"\"\"\n",
    "    # If we fail to read the magic number, then it will remain None, and thus\n",
    "    # we will invoke read_v3 (if mode is not strict), or raise IOError if mode\n",
    "    # is strict.\n",
    "    magicNumber = None\n",
    "    # We check if the handle is a file-like object. If it isn't, and the mode\n",
    "    # is strict, we raise an error. If it isn't and the mode isn't strict, we\n",
    "    # continue (perhaps somebody has got a CEL-file-like iterable, which used\n",
    "    # to work with previous versions of biopython and we don't want to maintain\n",
    "    # backwards compatibility).\n",
    "    try:\n",
    "        mode = handle.mode\n",
    "        # By definition an Affymetrix v4 CEL file has 64 as the first 4 bytes.\n",
    "        # Note that we use little-endian irrespective of the platform, again by\n",
    "        # definition.\n",
    "        position = handle.tell()\n",
    "        magicNumber = struct.unpack(\"<i\", handle.read(4))[0]\n",
    "    except (AttributeError, TypeError):\n",
    "        pass\n",
    "    except UnicodeDecodeError:\n",
    "        raise _modeError\n",
    "    finally:\n",
    "        try:\n",
    "            # reset the offset, to avoid breaking either v3 or v4.\n",
    "            handle.seek(position)\n",
    "        except AttributeError:\n",
    "            pass\n",
    "    if magicNumber != 64:\n",
    "        return read_v3(handle)\n",
    "\n",
    "    else:\n",
    "        return read_v4(handle)\n",
    "\n",
    "\n",
    "# read Affymetrix files version 4.\n",
    "def read_v4(f, headersOnly=False):\n",
    "    \"\"\" Reads Affymetrix CEL file, version 4, and returns a corresponding Record\n",
    "    object.\n",
    "\n",
    "    Most importantly record.intensities correspond to intensities from the CEL\n",
    "    file.\n",
    "\n",
    "    record.mask and record.outliers are not set.\n",
    "\n",
    "    Example Usage:\n",
    "\n",
    "    >>> from Bio.Affy import CelFile\n",
    "    >>> with open(\"Affy/affy_v4_example.CEL\", \"rb\") as handle:\n",
    "    ...     c = CelFile.read_v4(handle)\n",
    "    ...\n",
    "    >>> c.version == 4\n",
    "    True\n",
    "    >>> print(c.intensities.shape)\n",
    "    (5, 5)\n",
    "    \"\"\"\n",
    "    # We follow the documentation here:\n",
    "    # http://www.affymetrix.com/estore/support/developer/powertools/changelog/gcos-agcc/cel.html.affx\n",
    "    record = Record()\n",
    "    preHeaders = [\"magic\", \"version\", \"columns\", \"rows\", \"cellNo\", \"headerLen\"]\n",
    "    preHeadersMap = dict()\n",
    "    headersMap = dict()\n",
    "\n",
    "    # load pre-headers\n",
    "    try:\n",
    "        for name in preHeaders:\n",
    "            preHeadersMap[name] = struct.unpack(\"<i\", f.read(4))[0]\n",
    "    except UnicodeDecodeError as e:\n",
    "        raise _modeError\n",
    "\n",
    "    char = f.read(preHeadersMap[\"headerLen\"])\n",
    "    header = char.decode(\"ascii\", errors = \"ignore\")\n",
    "    for header in header.split(\"\\n\"):\n",
    "        if \"=\" in header:\n",
    "            header = header.split(\"=\")\n",
    "            headersMap[header[0]] = \"=\".join(header[1:])\n",
    "\n",
    "    # for debugging\n",
    "    # pp.pprint(\"preHeadersMap\")\n",
    "    # pp.pprint(preHeadersMap)\n",
    "    # pp.pprint(\"headersMap\")\n",
    "    # pp.pprint(headersMap)\n",
    "\n",
    "    record.version = preHeadersMap[\"version\"]\n",
    "    if record.version != 4:\n",
    "        raise ParserError(\"You are trying to parse CEL file version 4. This\"\n",
    "                         \" file violates the structure expected from CEL file\"\n",
    "                         \" version 4\")\n",
    "    record.GridCornerUL = headersMap[\"GridCornerUL\"]\n",
    "    record.GridCornerUR = headersMap[\"GridCornerUR\"]\n",
    "    record.GridCornerLR = headersMap[\"GridCornerLR\"]\n",
    "    record.GridCornerLL = headersMap[\"GridCornerLL\"]\n",
    "    record.DatHeader = headersMap[\"DatHeader\"]\n",
    "    record.Algorithm = headersMap[\"Algorithm\"]\n",
    "    record.AlgorithmParameters = headersMap[\"AlgorithmParameters\"]\n",
    "    record.NumberCells = preHeadersMap[\"cellNo\"]\n",
    "    # record.intensities are set below\n",
    "    # record.stdevs are set below\n",
    "    # record.npix are set below\n",
    "    record.nrows = int(headersMap[\"Rows\"])\n",
    "    record.ncols = int(headersMap[\"Cols\"])\n",
    "\n",
    "    # These cannot be reliably set in v4, because of discrepancies between real\n",
    "    # data and the documented format.\n",
    "    record.nmask = None\n",
    "    record.mask = None\n",
    "    record.noutliers = None\n",
    "    record.outliers = None\n",
    "    record.modified = None\n",
    "\n",
    "    # Real data never seems to have anything but zeros here, but we don't want\n",
    "    # to take chances. Raising an error is better than returning unreliable\n",
    "    # data.\n",
    "    def raiseBadHeader(field, expected):\n",
    "        actual = int(headersMap[field])\n",
    "        message = \"The header {field} is expected to be 0, not {value}\".format(value=actual, field=field)\n",
    "        if actual != expected:\n",
    "            raise ParserError(message)\n",
    "\n",
    "    raiseBadHeader(\"Axis-invertX\", 0)\n",
    "\n",
    "    raiseBadHeader(\"AxisInvertY\", 0)\n",
    "\n",
    "    raiseBadHeader(\"OffsetX\", 0)\n",
    "\n",
    "    raiseBadHeader(\"OffsetY\", 0)\n",
    "\n",
    "    # This is unfortunately undocumented, but it turns out that real data has\n",
    "    # the `record.AlgorithmParameters` repeated in the data section, until an\n",
    "    # EOF, i.e. b\"\\x04\".\n",
    "    char = b\"\\x00\"\n",
    "    safetyValve = 10**4\n",
    "    for i in range(safetyValve):\n",
    "        char = f.read(1)\n",
    "        # For debugging\n",
    "        # print([i for i in char], end=\"\")\n",
    "        if char == b\"\\x04\":\n",
    "            break\n",
    "        if i == safetyValve:\n",
    "            raise ParserError(\"Parse Error. The parser expects a short, \"\n",
    "                              \"undocumented binary blob terminating with \"\n",
    "                              \"ASCII EOF, x04\")\n",
    "\n",
    "    # After that there are precisely 15 bytes padded. Again, undocumented.\n",
    "    padding = f.read(15)\n",
    "\n",
    "    # That's how we pull out the values (triplets of the form float, float,\n",
    "    # signed short).\n",
    "    structa = struct.Struct(\"< f f h\")\n",
    "\n",
    "    # There are 10 bytes in our struct.\n",
    "    structSize = 10\n",
    "\n",
    "    # We initialise the most important: intensities, stdevs and npixs.\n",
    "    record.intensities = numpy.empty(record.NumberCells, dtype=float)\n",
    "    record.stdevs = numpy.empty(record.NumberCells, dtype=float)\n",
    "    record.npix = numpy.empty(record.NumberCells, dtype=int)\n",
    "\n",
    "    b = f.read(structSize * record.NumberCells)\n",
    "    if not headersOnly:\n",
    "        for i in range(record.NumberCells):\n",
    "            binaryFragment = b[i * structSize: (i + 1) * structSize]\n",
    "            intensity, stdevs, npix = structa.unpack(binaryFragment)\n",
    "            record.intensities[i] = intensity\n",
    "            # Turn these off, because we don't care\n",
    "            #record.stdevs[i] = stdevs\n",
    "            #record.npix[i] = npix\n",
    "\n",
    "        # reshape without copying.\n",
    "        def reshape(array):\n",
    "            view = array.view()\n",
    "            view.shape = (record.nrows, record.ncols)\n",
    "            return view\n",
    "\n",
    "        record.intensities = reshape(record.intensities)\n",
    "    return record"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Let us first load the data from the raw files into memory."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "from utils import *\n",
    "import re\n",
    "import os\n",
    "\n",
    "CEL_PATH = \"CEL_files\"\n",
    "\n",
    "MUSCLE_CELS = [filename for filename in os.listdir(CEL_PATH) if \"_M.CEL\" in filename and \".swp\" not in filename]\n",
    "#MUSCLE_RERUN_CELS = [filename for filename in os.listdir(CEL_PATH) if \"_MR.cel\" in filename and \".swp\" not in filename]\n",
    "#BLOOD_CELS = [filename for filename in os.listdir(CEL_PATH) if \"_B.CEL\" in filename and \".swp\" not in filename]\n",
    "\n",
    "#Let's not load muscle and blood CELs for now.\n",
    "MUSCLE_RERUN_CELS = []\n",
    "BLOOD_CELS = []\n",
    "\n",
    "ALL_CELS = MUSCLE_CELS + MUSCLE_RERUN_CELS + BLOOD_CELS\n",
    "\n",
    "#assertEqual(len(ALL_CELS), 76)\n",
    "#assertEqual(set(MUSCLE_CELS).intersection(set(MUSCLE_RERUN_CELS)), set())\n",
    "\n",
    "ALL_RECORDS = {}\n",
    "\n",
    "for filename in ALL_CELS:\n",
    "    with open(os.path.join(CEL_PATH, filename), \"rb\") as f:\n",
    "        record = read_v4(f, headersOnly=True)\n",
    "        ALL_RECORDS[filename] = record\n",
    "        record.npix = None\n",
    "        record.stdevs = None"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "collapsed": false
   },
   "source": [
    "# Then, let us extract HUEX IDs from DatHeader"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "FILE_TO_HUEX = {}\n",
    "\n",
    "for filename, record in ALL_RECORDS.items():\n",
    "    huexGroup = re.search(\"(\\d)*HUEX1A[\\d]*\", record.DatHeader)\n",
    "    if huexGroup:\n",
    "        huex = huexGroup.group()\n",
    "        FILE_TO_HUEX[filename] = huex"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Then let us map HUEX IDs onto allele length"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "ALLELE_PATH = \"alleleLength\"\n",
    "\n",
    "HUEX_TO_MOD = {}\n",
    "\n",
    "HUEX_TO_EST = {}\n",
    "\n",
    "BAD_HUEX = set()\n",
    "\n",
    "with open(ALLELE_PATH) as f:\n",
    "    for line in f:\n",
    "        line = line.rstrip().split(\"\\t\")\n",
    "        header = line[0]\n",
    "        ender = line[1:]\n",
    "        if header == \"IDs\":\n",
    "            IDs = ender\n",
    "        if header == \"EstProgAllele\":\n",
    "            EstProgAllele = ender\n",
    "        if header == \"ModalAllele\":\n",
    "            ModalAllele = ender\n",
    "    for id, est, mod in zip(IDs, EstProgAllele, ModalAllele):\n",
    "        count = False\n",
    "        try:\n",
    "            HUEX_TO_MOD[id] = int(mod)\n",
    "        except ValueError:\n",
    "            HUEX_TO_MOD[id] = None\n",
    "            BAD_HUEX.add(id)\n",
    "        try:\n",
    "            HUEX_TO_EST[id] = int(est)\n",
    "        except ValueError:\n",
    "            HUEX_TO_MOD[id] = None\n",
    "            BAD_HUEX.add(id)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "HUEX_TO_FILE_MUSCLE = {FILE_TO_HUEX[key] : key for key in MUSCLE_CELS}\n",
    "FILE_MUSCLE_TO_HUEX = {value: key for key, value in HUEX_TO_FILE_MUSCLE.items()}\n",
    "allMetadata = sorted([(HUEX_TO_MOD[huex], HUEX_TO_EST[huex],  huex, filename) for huex, filename in HUEX_TO_FILE_MUSCLE.items() if huex not in BAD_HUEX])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "assertEqual(len(BAD_HUEX), 1)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "assertEqual(len(MUSCLE_CELS), len(HUEX_TO_FILE_MUSCLE))\n",
    "assertEqual(len(HUEX_TO_FILE_MUSCLE), len(FILE_MUSCLE_TO_HUEX))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "metadata": {
    "collapsed": false
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "{'190281HUEX1A11': '427374914_M.CEL', '189749HUEX1A11': '117440822_M.CEL', '190283HUEX1A11': '549452228_M.CEL', '189740HUEX1A11': '159834720_M.CEL', '189737HUEX1A11': '873750289_M.CEL', '190285HUEX1A11': '661252781_M.CEL', '189741HUEX1A11': '270148799_M.CEL', '189738HUEX1A11': '830225708_M.CEL', '190278HUEX1A21': '204472077_M.CEL', '190287HUEX1A11': '896445336_M.CEL', '189819HUEX1A11': '881676366_M.CEL', '189745HUEX1A11': '406335477_M.CEL', '189822HUEX1A11': '360448352_M.CEL', '189747HUEX1A11': '572448109_M.CEL', '190280HUEX1A11': '420299717_M.CEL', '189823HUEX1A11': '111747589_M.CEL', '189748HUEX1A11': '597785396_M.CEL', '189746HUEX1A11': '449599671_M.CEL', '190286HUEX1A11': '819054051_M.CEL', '189751HUEX1A11': '387939296_M.CEL', '189743HUEX1A11': '321962190_M.CEL', '190284HUEX1A11': '575039926_M.CEL', '189821HUEX1A11': '419550533_M.CEL', '189744HUEX1A11': '328687703_M.CEL', '189820HUEX1A11': '377666471_M.CEL', '189739HUEX1A11': '129523253_M.CEL', '190279HUEX1A11': '230974357_M.CEL', '189750HUEX1A11': '124563003_M.CEL', '190282HUEX1A11': '473208969_M.CEL', '189742HUEX1A11': '315805040_M.CEL'}\n"
     ]
    }
   ],
   "source": [
    "print(HUEX_TO_FILE_MUSCLE)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "collapsed": true
   },
   "source": [
    "# It turns out we have all the IDs we want, and we know allele lengths for all the patients except one.\n",
    "\n",
    "The patient refused blood donation after the 3rd unsucessful attempt."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Now, let us look at the CDF file\n",
    "\n",
    "The CDF file contains information mapping transcription clusters onto physical coordinates on the chip."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "import sys\n",
    "contextDict = {}\n",
    "\n",
    "with open(os.path.join(CEL_PATH, \"HuEx-1_0-st-v2.text.cdf\")) as f:\n",
    "    lines = f.readlines()\n",
    "    context = None\n",
    "    for line in lines:\n",
    "        line = line.rstrip()\n",
    "        if line:\n",
    "            c1 = line[0] == \"[\"\n",
    "            c2 = \"Unit\" in line\n",
    "            c3 = \"_Block1]\" in line\n",
    "            checkConds = [c1, c2, c3]\n",
    "            if all(checkConds):\n",
    "                context = line[len(\"Unit\") + 1: -1 * len(\"_Block1\") - 1]\n",
    "                if context in contextDict:\n",
    "                    print(line)\n",
    "                    raise ValueError\n",
    "                else:\n",
    "                    contextDict[context] = {}\n",
    "            elif context is not None:\n",
    "                eqPos = line.find(\"=\")\n",
    "                key = line[:eqPos]\n",
    "                matchedList = re.findall(\"Cell[1-9]+\", key)\n",
    "                if matchedList:\n",
    "                    value = line[eqPos + 1:].split(\"\\t\")\n",
    "                    contextDict[context][key] = value[:3]\n",
    "        else:\n",
    "            context = None"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 23,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "def extractIntensity(record, coord):\n",
    "    # It is important to reverse the coordinates from Row/Column into X/Y\n",
    "    return record.intensities[coord[1], coord[0]]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 28,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "import redis\n",
    "import json\n",
    "\n",
    "allMetadata.sort()\n",
    "    \n",
    "if wipeDB:\n",
    "    r.flushdb()\n",
    "\n",
    "r.set(\"main$alleleData\", json.dumps(allMetadata))\n",
    "\n",
    "def upsertProbes(probeset, probes):\n",
    "    r.hset(\"probes$metadata\", probeset, json.dumps(probes))\n",
    "\n",
    "def appendData(probeset, probes, record):\n",
    "    record = record[0]\n",
    "    intensities = []\n",
    "    for _, X, Y in probes:\n",
    "        intens = extractIntensity(record, [X, Y])\n",
    "        intensities.append(int(intens))\n",
    "    r.lpush(\"probes$probeset$\" + probeset, json.dumps(intensities))\n",
    "\n",
    "def iterateOverContext(upperLimit, callable, extraArgs = None):\n",
    "    gen = contextDict.items()\n",
    "    for i, (probeset, XYseq) in enumerate(gen):\n",
    "        if i == recordNo:\n",
    "            break\n",
    "        probes = []\n",
    "        for cell, (X, Y, Seq) in XYseq.items():\n",
    "            probes.append((Seq, int(X), int(Y)))\n",
    "        probes.sort()\n",
    "        if extraArgs:\n",
    "            callable(probeset, probes, extraArgs)\n",
    "        else:\n",
    "            callable(probeset, probes)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# That's the dangerous and time-consuming bit, where we iterate over all intensities of all patients and put them in the database"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 29,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "iterateOverContext(recordNo, upsertProbes)\n",
    "for modAllele, progAllele, huexID, filename in allMetadata:\n",
    "    with open(os.path.join(CEL_PATH, filename), \"rb\") as f:\n",
    "        record = CELFile.read_v4(f)\n",
    "        record.npix = None\n",
    "        record.stdevs = None\n",
    "        iterateOverContext(recordNo, appendData, extraArgs=[record])\n",
    "r.save()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {
    "collapsed": false
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       "b'[[11, 11, \"189822HUEX1A11\", \"360448352_M.CEL\"], [12, 12, \"189747HUEX1A11\", \"572448109_M.CEL\"], [12, 12, \"189748HUEX1A11\", \"597785396_M.CEL\"], [12, 12, \"189751HUEX1A11\", \"387939296_M.CEL\"], [83, 80, \"190284HUEX1A11\", \"575039926_M.CEL\"], [186, 158, \"190280HUEX1A11\", \"420299717_M.CEL\"], [240, 199, \"189737HUEX1A11\", \"873750289_M.CEL\"], [261, 155, \"189820HUEX1A11\", \"377666471_M.CEL\"], [290, 186, \"189743HUEX1A11\", \"321962190_M.CEL\"], [297, 227, \"189738HUEX1A11\", \"830225708_M.CEL\"], [297, 227, \"189749HUEX1A11\", \"117440822_M.CEL\"], [345, 243, \"190282HUEX1A11\", \"473208969_M.CEL\"], [373, 243, \"190278HUEX1A21\", \"204472077_M.CEL\"], [408, 211, \"189739HUEX1A11\", \"129523253_M.CEL\"], [561, 411, \"190286HUEX1A11\", \"819054051_M.CEL\"], [571, 297, \"189745HUEX1A11\", \"406335477_M.CEL\"], [593, 301, \"189750HUEX1A11\", \"124563003_M.CEL\"], [604, 439, \"190283HUEX1A11\", \"549452228_M.CEL\"], [654, 318, \"189744HUEX1A11\", \"328687703_M.CEL\"], [697, 397, \"190287HUEX1A11\", \"896445336_M.CEL\"], [740, 506, \"189741HUEX1A11\", \"270148799_M.CEL\"], [866, 341, \"189819HUEX1A11\", \"881676366_M.CEL\"], [872, 600, \"189823HUEX1A11\", \"111747589_M.CEL\"], [993, 565, \"190279HUEX1A11\", \"230974357_M.CEL\"], [999, 745, \"190285HUEX1A11\", \"661252781_M.CEL\"], [1000, 453, \"189746HUEX1A11\", \"449599671_M.CEL\"], [1035, 695, \"189740HUEX1A11\", \"159834720_M.CEL\"], [1111, 627, \"189742HUEX1A11\", \"315805040_M.CEL\"], [1261, 703, \"190281HUEX1A11\", \"427374914_M.CEL\"]]'"
      ]
     },
     "execution_count": 9,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    " "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {
    "collapsed": false
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       "b'[[\"AACAAGGGACACTCATTGCGGGAAC\", 2518, 1946], [\"ACGACGTAACGATCTGACGGAAAAG\", 1364, 263], [\"CAGTGGTCCAAACGATACAATACAT\", 1802, 1380], [\"CTCGGTAGGAAAGAACCCCGTATGT\", 1783, 123]]'"
      ]
     },
     "execution_count": 9,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "r.hget(\"probes$metadata\", 3973794)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "metadata": {
    "collapsed": false
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "probes$probeset$2346130\n",
      "0 b'[66, 81, 106, 90]'\n",
      "1 b'[61, 66, 94, 94]'\n",
      "2 b'[61, 39, 140, 47]'\n",
      "3 b'[49, 47, 82, 56]'\n",
      "4 b'[82, 69, 136, 72]'\n",
      "5 b'[36, 46, 134, 63]'\n",
      "6 b'[77, 72, 87, 68]'\n",
      "7 b'[59, 59, 125, 75]'\n",
      "8 b'[67, 70, 110, 86]'\n",
      "9 b'[100, 85, 118, 73]'\n",
      "10 b'[94, 84, 100, 74]'\n",
      "11 b'[66, 49, 66, 68]'\n",
      "12 b'[40, 44, 36, 50]'\n",
      "13 b'[42, 56, 76, 51]'\n",
      "14 b'[95, 75, 85, 65]'\n",
      "15 b'[75, 57, 138, 73]'\n",
      "16 b'[49, 58, 77, 50]'\n",
      "17 b'[38, 58, 53, 47]'\n",
      "18 b'[45, 35, 64, 59]'\n",
      "19 b'[56, 68, 89, 66]'\n",
      "20 b'[63, 53, 96, 87]'\n",
      "21 b'[64, 46, 94, 42]'\n",
      "22 b'[72, 72, 131, 59]'\n",
      "23 b'[58, 82, 96, 54]'\n",
      "24 b'[53, 34, 60, 64]'\n",
      "25 b'[35, 38, 61, 46]'\n",
      "26 b'[62, 59, 86, 52]'\n",
      "27 b'[73, 61, 113, 70]'\n",
      "28 b'[48, 37, 60, 43]'\n"
     ]
    }
   ],
   "source": [
    "address = \"probes$probeset$\" + \"2346130\"\n",
    "print(address)\n",
    "length = r.llen(address)\n",
    "for i in range(length):\n",
    "    print(i, r.lindex(address, i))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "anaconda-cloud": {},
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.6.0"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 0
}
